from groq import Groq
import json
import traceback
import ast

from config import GROQ_API_KEY
from helper import *

if not GROQ_API_KEY:
    raise ValueError("API key for Groq not found.")


client = Groq(api_key=GROQ_API_KEY)

def run_query_and_get_data(required_query, current_conversation):
    """
    Executes a SQL query and handles errors or no-data responses by interacting with the chat model
    to iteratively refine the query up to 3 attempts.

    Parameters:
        required_query (str): The initial SQL query string to execute.
        current_conversation (object): An object representing the current conversation state,
                                       which contains a `messages` list to append user feedback
                                       for query correction.

    Behavior:
        - Attempts to run the provided SQL query up to 3 times.
        - Uses `apply_query_sql` to execute the query and expects a tuple of
          (data, flag, errorMsg):
            * If `flag` is 'Error', appends an error message to the conversation prompting
              correction and asks the chat model for a revised query.
            * If `flag` is 'No Data', appends a no-data message to the conversation and asks
              for a new query.
            * If successful (flag neither 'Error' nor 'No Data'), returns the query result data.
        - For each retry, obtains a new query from `chat_with_groq` based on the updated conversation.
        - Stops retrying after 3 attempts or upon success.

    Returns:
        list or None: Returns the data (list of rows) from a successful query execution.
                      Returns None if all 3 attempts fail or no valid data is returned.

    Notes:
        - The function expects the chat model to respond with a string representation of a dictionary
          containing a 'query' key.
        - The returned query from the chat model is sanitized to remove line breaks before execution.
    """
    
    counter = 0
    data, flag, errorMsg = None, None, None
    while counter < 3 and not data:
        print(f"Generated SQL Query: {required_query}")
        data, flag, errorMsg = apply_query_sql(required_query, is_read=True)
        if flag == 'Error':
            current_conversation.messages.append({
                "role": "user",
                "content": f"The query you wrote returned error. Error: '{errorMsg}'. Fix the mentioned error and try again."
            })
        elif flag == 'No Data':
            current_conversation.messages.append({
                "role": "user",
                "content": f"The query you wrote returned no data. Please try again with a different query."
            })
        else:
            return data
        response = chat_with_groq(current_conversation)
        response_dict = ast.literal_eval(response)
        required_query = response_dict['query'].replace("\n", " ")
        counter += 1
    return None

def chat_with_groq(current_conversation):
    """
    Sends the current conversation to the Groq API and returns the generated response.

    This function:
        - Uses the 'llama-3.1-8b-instant' model to generate a response based on the input messages.
        - Streams the response incrementally and concatenates it into a single string.

    Parameters:
        current_conversation (object): An object containing the conversation history.
                                       It must have a `.messages` attribute, which is a list of
                                       message dictionaries compatible with the Groq chat API format.

    Returns:
        str: The full response generated by the Groq model as a single string.

    Side Effects:
        - Prints the complete response to the console for debugging purposes.

    Notes:
        - Model used: llama-3.1-8b-instant
        - Response is streamed and assembled from chunks.
        - Assumes the `client` object is a valid, pre-authenticated Groq client instance.
    """

    completion = client.chat.completions.create(
            model="llama-3.1-8b-instant",
            messages=current_conversation.messages,
            temperature=1,
            max_tokens=1024,
            top_p=1,
            stream=True,
            stop=None,
        )
    
    response = ""
    for chunk in completion:
        response += chunk.choices[0].delta.content or ""
    
    print(f"Response from Groq: {response}")
    return response

def driver_function(current_conversation):
    """
    Driver function to manage the end-to-end process of handling a conversation with the Groq model.

    This function:
        1. Sends the current conversation to the Groq model via `chat_with_groq`.
        2. Parses the returned response to extract the generated SQL query.
        3. Executes the query using `apply_query_sql`.
        4. Returns the resulting data, if any.

    Parameters:
        current_conversation (list or str): The ongoing conversation or prompt history to be sent to the Groq model.

    Returns:
        list[dict] or str or None:
            - A list of dictionaries (query result as JSON-like format) if data is successfully retrieved.
            - A string message if an error occurs during processing.
            - None if no query was generated or no data was returned from the database.

    Side Effects:
        - Prints messages for debugging such as the generated SQL query and any errors encountered.

    Exceptions:
        - Catches and logs any exceptions using `traceback.format_exc()` and returns a user-friendly error message.
    """

    try:
        response = chat_with_groq(current_conversation)    
        response_dict = ast.literal_eval(response)  # Safely parse the response string to a dictionary
        required_query = response_dict['query'].replace("\n", " ")
        data = run_query_and_get_data(required_query, current_conversation)

        return data
    except Exception as e:
        print(traceback.format_exc())
        return "An error occurred while processing your request."
